{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decisionTree-MlLib.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajprakrit/ML-Library-1/blob/master/decisionTree_MlLib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA-HcTJJjiZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wSt83Cmj4kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log2(x):#function for log base 2\n",
        "\n",
        "  return np.log(x)/np.log(2)\n",
        "\n",
        "def entropy(sample_entries, n_samples):#entropy\n",
        "\n",
        "  p = sample_entries/n_samples\n",
        "\n",
        "  return (-1.0*p) * log2(p)\n",
        "\n",
        "def child_entropy(division):#entropy in a sample with more than one labels\n",
        "  \n",
        "  Sum = 0;\n",
        "  n = len(division)\n",
        "  classes = set(division)\n",
        "\n",
        "  for c in classes:\n",
        "    size_class = np.sum(c==division)\n",
        "    if size_class == 0:\n",
        "      continue\n",
        "    c_entr = entropy(size_class, n)\n",
        "    Sum += c_entr\n",
        "\n",
        "  return Sum, n\n",
        "\n",
        "def avg_entropy(y_predicted, y):#y_predicted is a boolean array which would be created on setting threshold\n",
        "\n",
        "  entrChild1, n_child1 = child_entropy(y[y_predicted])\n",
        "  entrChild2, n_child2 = child_entropy(y[~y_predicted])\n",
        "\n",
        "  return ((n_child1/n) * entrChild1) + ((n_child2/n) * entrChild2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIOSclw89Dyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTreeClassifier:\n",
        "\n",
        "  def __init__(self, max_depth):\n",
        "\n",
        "    self.max_depth = max_depth\n",
        "    self.depth = 0\n",
        "\n",
        "  def best_split(self, feature, y):\n",
        "    '''\n",
        "      feature : column of the feature on which we split\n",
        "      y : target variable\n",
        "    '''\n",
        "\n",
        "    min_entropy = 20  #initializing a large value for entropy to get to a min optimal case\n",
        "    for value in set(feature):\n",
        "      y_predicted = feature < value\n",
        "      my_entropy = avg_entropy(y_predicted, y)\n",
        "\n",
        "      if my_entropy <= min_entropy:\n",
        "        min_entropy = my_entropy\n",
        "        threshold = value\n",
        "\n",
        "    return min_entropy, threshold\n",
        "\n",
        "  def best_split_all(self, X, y):\n",
        "    '''X : whole sample on that node\n",
        "       y : target variable\n",
        "    '''\n",
        "    \n",
        "    X1 = X.T\n",
        "    global_min_entropy = 20\n",
        "    idx = 0\n",
        "\n",
        "    for feature in X1:\n",
        "      '''considering all the features for deciding split and all the threshold inside the features.\n",
        "         time complexity will be O(features*samples)\n",
        "      '''\n",
        "      \n",
        "      feature_min_entropy, threshold = self.best_split(feature, y)\n",
        "\n",
        "      if feature_min_entropy == 0:\n",
        "\n",
        "        return idx, threshold, feature_min_entropy\n",
        "\n",
        "      if feature_min_entropy <= global_min_entropy:\n",
        "\n",
        "        global_min_entropy = feature_min_entropy\n",
        "        cutoff = threshold\n",
        "        col_no = idx\n",
        "      \n",
        "      idx+=1\n",
        "\n",
        "    return idx, cutoff, global_min_entropy\n",
        "\n",
        "  def #stopped because can't apply recurrsion and store values \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpSWI8Z_ZeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression ML-Lib.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajprakrit/ML-Library-1/blob/master/LogisticRegression_ML_Lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FwiAVZ1ZRgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zS6wlZ3cZ6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  '''\n",
        "  defining a class for training a logistic regression model\n",
        "  '''\n",
        "\n",
        "  def __init__(self, alpha, n_iters, n_class):  #default value for parameters are set\n",
        "    '''\n",
        "    init parameters are set for every object of this class\n",
        "    ''' \n",
        "\n",
        "    self.alpha = alpha\n",
        "    self.n_iters = n_iters\n",
        "    self.n_class= n_class\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    ''' we basically initialize parameters for every class and optimize the cost over the parameters for that particular class.\n",
        "    So, our loop runs n_class * n_iters times and we end up in optimizing all the parametrs.\n",
        "    One vs all method is used so that it can be interpreted in the form of a binary classification problem.For particular class(label)\n",
        "    it is cosidered as 1 and other labels a 0.The above interpretation makes our traing equivalent to traing ten binary classification models'''\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "    # init parameters are initialized(defined for every object in class)\n",
        "    self.weights = np.zeros([self.n_class, n_features]) #we define weights for every class(here 0 to 9)\n",
        "    self.bias = np.zeros([self.n_class])\n",
        "\n",
        "    for i in range (self.n_iters):\n",
        "      y_predicted = self.hypothesis(X)  #hypothestis function\n",
        "      y_predicted = self.sigmoid(y_predicted) #using sigmoid method of class to consider sigmoid function\n",
        "\n",
        "      for j in range(self.n_class): # considering every class(using one vs all method) and updating weights\n",
        "        y_class = np.zeros([n_samples])\n",
        "        for k in range(n_samples):# taking particular class as 1 and other as 0\n",
        "          if y[k]==j:\n",
        "            y_class[k] = 1\n",
        "\n",
        "        dw = (1/n_samples) * ((X.T) @ (y_predicted[:,j] - y_class)) #calculating weights\n",
        "        db = (1/n_samples) * (np.sum(y_predicted[:,j] - y_class))\n",
        "\n",
        "        self.weights[j] -= self.alpha * (dw) #updating weights and bias\n",
        "        self.bias[j] -= self.alpha * (db)\n",
        "\n",
        "\n",
        "  def hypothesis(self, X):\n",
        "    return (X @ ((self.weights).T)) + self.bias\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    '''predict method predict the target as the label with highest value of sigmoid of the hypothesis'''\n",
        "\n",
        "    y_predicted = X @ ((self.weights).T) + self.bias\n",
        "    y_predicted = self.sigmoid(y_predicted)\n",
        "    predictions = [np.argmax(i) for i in y_predicted] #predicting the label with max value of sigmoid\n",
        "    return predictions\n",
        "        \n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    '''a method to calculate sigmoid function'''\n",
        "\n",
        "    return 1./(1+np.exp(-x))\n",
        "\n",
        "  def _accuracy(self, X, y): \n",
        "    '''accuray of our model taking into account the predictions and actual output'''\n",
        "\n",
        "    X = self.predict(X)\n",
        "    acc = np.sum(X == y)/len(y)\n",
        "    return acc*100\n",
        "\n",
        "  def train_test_split(self, X, y, ratio): #creating a method for train test split of our dataset\n",
        "    ''' a simple method that splits data into train and test samples'''\n",
        "\n",
        "    size = X.shape[0];\n",
        "    count = size*(1-ratio)\n",
        "    count = int(count)\n",
        "    X_train = X[:count]\n",
        "    y_train = y[:count]\n",
        "    X_test = X[count:]\n",
        "    y_test = y[count:]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7X61h7_dB_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = datasets.load_digits() #getting mnist dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msqpdMjRR59-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = mnist.data, mnist.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cca7T5aOSc_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LogisticRegression(0.01, 1000, 10) #creating object regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gCvr1uSiZmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = clf.train_test_split(X, y, 0.2) #splitting data into 80 to 20 ratio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlyFDja7SypV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.fit(X_train, y_train) #training our model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLb2sFH8S170",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WpGWdQzUzxj",
        "colab_type": "code",
        "outputId": "186b992b-9daf-4a3c-b1c7-cf2a6c5d15a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf._accuracy(X_test, y_test) #fetching accuracy of our model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90.83333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCbMTkWuItYZ",
        "colab_type": "text"
      },
      "source": [
        "USING SKLEARN TO TRAIN OUR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tROXoIMcU6Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccjuC3SPJx3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt6y0DtMJ3qJ",
        "colab_type": "code",
        "outputId": "0d7e16b7-f627-4684-d95b-3947a51a3d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "clf1.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog3V6AkJ9kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = clf1.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg7J1s2qKSe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = np.sum(predictions == y_test)/len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmlsDl3SKY5L",
        "colab_type": "code",
        "outputId": "4f8d4917-b272-40c4-fb8c-77902bd4851f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8972222222222223"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1b28s7IKcc5",
        "colab_type": "code",
        "outputId": "ee26166f-333c-40c9-9c8e-e82536723ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy * 100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.72222222222223"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ceAFPDjKjjY",
        "colab_type": "text"
      },
      "source": [
        "**accuracy from our model is  90.83% and that from sklearn is 89.72%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOl7stHfKgKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_ML_Lib.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajprakrit/ML-Library-1/blob/master/ANN_ML_Lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPiz9rMympiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ssprrMrmzjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_split(X, y, ratio):##train test split method\n",
        "\n",
        "        size = X.shape[0];\n",
        "        count = size*(1-ratio)\n",
        "        count = int(count)\n",
        "        X_train = X[:count]\n",
        "        y_train = y[:count]\n",
        "        X_test = X[count:]\n",
        "        y_test = y[count:]\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        "def sigmoid(X): #sigmoid function\n",
        "\n",
        "  return 1./(1 + np.exp(-X))\n",
        "\n",
        "def sigmoid_derv(X): #derivative of sigmoid\n",
        "\n",
        "  return X * (1 - X)\n",
        "\n",
        "def softmax(X): #softmax function to generalize output layer such that sum of all outputs is one \n",
        "\n",
        "  exponentials = np.exp(X - np.max(X, axis = 1, keepdims = True))\n",
        "\n",
        "  return exponentials/(np.sum(exponentials, axis = 1, keepdims = True))\n",
        "\n",
        "def cross_entropy(pred, real): \n",
        "\n",
        "    n_samples = real.shape[0]\n",
        "    res = pred - real\n",
        "    return res/n_samples\n",
        "\n",
        "def error(pred, real): #cross entropy function for error\n",
        "\n",
        "    n_samples = real.shape[0]\n",
        "    logp = - np.log(pred[np.arange(n_samples), real.argmax(axis=1)])\n",
        "    loss = np.sum(logp)/n_samples\n",
        "    return loss\n",
        "\n",
        "class MyANN:\n",
        "\n",
        "  def __init__(self, X, y, nodes, lr, n_class):\n",
        "    self.X = X\n",
        "    self.nodes = nodes\n",
        "    n_samples, n_features = X.shape\n",
        "    self.n_class = n_class\n",
        "    self.lr = lr\n",
        "    #initialization of parameters of class object\n",
        "    self.w1 = np.random.randn(n_features, self.nodes)\n",
        "    self.b1 = np.zeros((1, self.nodes))\n",
        "    self.w2 = np.random.randn(self.nodes, self.nodes)\n",
        "    self.b2 = np.zeros((1, self.nodes))\n",
        "    self.w3 = np.random.randn(self.nodes, self.n_class)\n",
        "    self.b3 = np.zeros((1, self.n_class))\n",
        "    self.y = y\n",
        "\n",
        "  def forwardprop(self):\n",
        "    #forward propagation using matrix multiplication \n",
        "    z1 = np.dot(self.X, self.w1) + self.b1\n",
        "    self.a1 = sigmoid(z1)\n",
        "    z2 = np.dot(self.a1, self.w2) + self.b2\n",
        "    self.a2 = sigmoid(z2)\n",
        "    z3 = np.dot(self.a2, self.w3) + self.b3\n",
        "    self.a3 = softmax(z3)\n",
        "\n",
        "  def backprop(self):\n",
        "    loss = error(self.a3, self.y)\n",
        "    print('Error :', loss)\n",
        "    #calculating delta of every layer using chain rule\n",
        "    a3_delta = cross_entropy(self.a3, self.y) \n",
        "    z2_delta = np.dot(a3_delta, self.w3.T)\n",
        "    a2_delta = z2_delta * sigmoid_derv(self.a2) \n",
        "    z1_delta = np.dot(a2_delta, self.w2.T)\n",
        "    a1_delta = z1_delta * sigmoid_derv(self.a1) \n",
        "\n",
        "    #updating weights between every layer\n",
        "    self.w3 -= self.lr * np.dot(self.a2.T, a3_delta)\n",
        "    self.b3 -= self.lr * np.sum(a3_delta, axis=0, keepdims=True)\n",
        "    self.w2 -= self.lr * np.dot(self.a1.T, a2_delta)\n",
        "    self.b2 -= self.lr * np.sum(a2_delta, axis=0)\n",
        "    self.w1 -= self.lr * np.dot(self.X.T, a1_delta)\n",
        "    self.b1 -= self.lr * np.sum(a1_delta, axis=0)\n",
        "\n",
        "  def fit(self, n_iters):\n",
        "\n",
        "    for i in range(n_iters):\n",
        "      self.forwardprop()\n",
        "      self.backprop()\n",
        "\n",
        "  def accuracy(self, test, y):\n",
        "\n",
        "    self.test = test\n",
        "    self.forwardprop()\n",
        "    predicted_label = [ np.argmax(i) for i in self.a3]\n",
        "    acc = 0\n",
        "    for i in range(self.test.shape[0]):\n",
        "      if y[i][predicted_label[i]]==1:\n",
        "        acc+=1\n",
        "\n",
        "    acc = acc/self.test.shape[0]\n",
        "\n",
        "    return acc*100\n",
        "\n",
        "  def predict(self, test):\n",
        "\n",
        "    self.test = test\n",
        "    self.forwardprop()\n",
        "    \n",
        "\n",
        "    return [np.argmax(i) for i in self.a3] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnh6whc7piEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('sample_data/mnist_train_small.csv', header = None)\n",
        "df1 = pd.read_csv('sample_data/mnist_test.csv', header = None)\n",
        "X_train = np.array(df.iloc[:, 1:785])\n",
        "y_train1 = np.array(df.iloc[:, 0])\n",
        "X_test = np.array(df1.iloc[:, 1:785])\n",
        "y_test1 = np.array(df1.iloc[:, 0])\n",
        "def scaling(X):\n",
        "  return (X - np.mean(X))/(np.max(X) - np.min(X) + 1)\n",
        "\n",
        "X_test = scaling(X_test)\n",
        "X_train = scaling(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI1dv-P9prdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.zeros([X_train.shape[0], 10])\n",
        "for i in range(X_train.shape[0]):\n",
        "  y_train[i][y_train1[i]] = 1\n",
        "\n",
        "y_test = np.zeros([X_test.shape[0], 10])\n",
        "for i in range(X_test.shape[0]):\n",
        "  y_test[i][y_test1[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wiFKSgdptmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = MyANN(X_train, y_train, 10, 0.5, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6saDlp9Vp0bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.fit(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho1yecsXqAZv",
        "colab_type": "code",
        "outputId": "7f1a4621-03a4-4c93-a31c-368323024658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.accuracy(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.585"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Z31xQa3lOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zgZ-vZ39ZCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[np.argmax(i) for i in predict]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymK_il4U9aO6",
        "colab_type": "code",
        "outputId": "296ae454-b34c-47f7-e513-de5ed1d2f32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eRuBmSp95IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}